{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-01T16:09:49.132943Z",
     "start_time": "2024-12-01T16:09:49.113161Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from langgraph.graph import START, END, StateGraph, MessagesState\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "load_dotenv()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T16:09:49.410603Z",
     "start_time": "2024-12-01T16:09:49.396315Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def initialization(file: str):    \n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=os.getenv(\"OPENAI_API_JEY\"))\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\", api_key=os.getenv(\"OPENAI_API_JEY\"))\n",
    "    vector_store = Chroma(embedding_function=embeddings)\n",
    "    loader = PyPDFLoader(file_path=file, extract_images=True)\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    \n",
    "    docs = loader.load()\n",
    "    all_splits = text_splitter.split_documents(docs)\n",
    "    _ = vector_store.add_documents(documents=all_splits)\n",
    "    \n",
    "    graph_builder = StateGraph(MessagesState)\n",
    "    \n",
    "    @tool(response_format=\"content_and_artifact\")\n",
    "    def retrieve(query: str):\n",
    "        \"\"\"Retrieve information related to a query.\"\"\"\n",
    "        retrieved_docs = vector_store.similarity_search(query, k=2)\n",
    "        serialized = \"\\n\\n\".join(\n",
    "            (f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")\n",
    "            for doc in retrieved_docs\n",
    "        )\n",
    "        return serialized, retrieved_docs\n",
    "    \n",
    "    def query_or_respond(state: MessagesState):\n",
    "        llm_with_tools = llm.bind_tools([retrieve])\n",
    "        response = llm_with_tools.invoke(state[\"messages\"])\n",
    "        return {\"messages\": [response]}\n",
    "    \n",
    "    tools = ToolNode([retrieve])\n",
    "    \n",
    "    def generate(state: MessagesState):\n",
    "        \"\"\"Generate answer.\"\"\"\n",
    "        # Get generated ToolMessages\n",
    "        recent_tool_messages = []\n",
    "        for message in reversed(state[\"messages\"]):\n",
    "            if message.type == \"tool\":\n",
    "                recent_tool_messages.append(message)\n",
    "            else:\n",
    "                break\n",
    "        tool_messages = recent_tool_messages[::-1]\n",
    "    \n",
    "        # Format into prompt\n",
    "        docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
    "        system_message_content = (\n",
    "            \"You are an assistant for question-answering tasks. \"\n",
    "            \"Use the following pieces of retrieved context to answer \"\n",
    "            \"the question. If you don't know the answer, say that you \"\n",
    "            \"don't know. Use three sentences maximum and keep the \"\n",
    "            \"answer concise.\"\n",
    "            \"\\n\\n\"\n",
    "            f\"{docs_content}\"\n",
    "        )\n",
    "        conversation_messages = [\n",
    "            message\n",
    "            for message in state[\"messages\"]\n",
    "            if message.type in (\"human\", \"system\")\n",
    "            or (message.type == \"ai\" and not message.tool_calls)\n",
    "        ]\n",
    "        prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
    "    \n",
    "        # Run\n",
    "        response = llm.invoke(prompt)\n",
    "        return {\"messages\": [response]}\n",
    "    \n",
    "    graph_builder.add_node(query_or_respond)\n",
    "    graph_builder.add_node(tools)\n",
    "    graph_builder.add_node(generate)\n",
    "    \n",
    "    graph_builder.set_entry_point(\"query_or_respond\")\n",
    "    graph_builder.add_conditional_edges(\n",
    "        \"query_or_respond\",\n",
    "        tools_condition,\n",
    "        {END: END, \"tools\": \"tools\"},\n",
    "    )\n",
    "    graph_builder.add_edge(\"tools\", \"generate\")\n",
    "    graph_builder.add_edge(\"generate\", END)\n",
    "    \n",
    "    graph = graph_builder.compile()\n",
    "    \n",
    "    return graph"
   ],
   "id": "153ee4ccda0e2978",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T16:09:49.960339Z",
     "start_time": "2024-12-01T16:09:49.903943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "graph = initialization()\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "\n"
   ],
   "id": "d434a2554dd29558",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "initialization() missing 1 required positional argument: 'file'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[76], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mIPython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdisplay\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Image, display\n\u001B[0;32m----> 3\u001B[0m graph \u001B[38;5;241m=\u001B[39m \u001B[43minitialization\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m display(Image(graph\u001B[38;5;241m.\u001B[39mget_graph()\u001B[38;5;241m.\u001B[39mdraw_mermaid_png()))\n",
      "\u001B[0;31mTypeError\u001B[0m: initialization() missing 1 required positional argument: 'file'"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T16:09:51.183226Z",
     "start_time": "2024-12-01T16:09:50.151412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_message = \"Hello\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ],
   "id": "9732a86e3114b0b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Hello\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T16:09:54.351825Z",
     "start_time": "2024-12-01T16:09:51.184611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_message = \"What is Money laundering?\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ],
   "id": "8ded9dd24fa86f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "What is Money laundering?\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve (call_bbG2dXDjnapLb88fvCOGRKXF)\n",
      " Call ID: call_bbG2dXDjnapLb88fvCOGRKXF\n",
      "  Args:\n",
      "    query: What is money laundering?\n",
      "=================================\u001B[1m Tool Message \u001B[0m=================================\n",
      "Name: retrieve\n",
      "\n",
      "Source: {'page': 0, 'source': 'data/AML_IEEE_ACCESS_2024.pdf'}\n",
      "Content: I. INTRODUCTION\n",
      "Money laundering is a globally challenging economic\n",
      "concern. TheUN Vienna 1988 Convention describes it as\n",
      "‘‘the conversion or transfer of property, knowing that such\n",
      "property is derived from any offence (s), to conceal or\n",
      "The associate editor coordinating the review of this manuscript and\n",
      "approving it for publication was Ines Domingues\n",
      ".\n",
      "disguise the illicit origin of the property or of assisting any\n",
      "person who is involved in such offence (s) to evade the legal\n",
      "consequences of his actions. ’’. Being a global issue, money\n",
      "laundering results in approximately 0.8 to 2.0$ trillion being\n",
      "laundered every year, which equates to 2 to 5% of the world’s\n",
      "GDP [1], [2]. Being a global issue, money laundering results\n",
      "in approximately 0.8 to 2.0$ trillion being laundered every\n",
      "year, which equates to 2 to 5% of the world’s GDP [2].\n",
      "50012\n",
      "\n",
      "Source: {'page': 0, 'source': 'data/AML_IEEE_ACCESS_2024.pdf'}\n",
      "Content: I. INTRODUCTION\n",
      "Money laundering is a globally challenging economic\n",
      "concern. TheUN Vienna 1988 Convention describes it as\n",
      "‘‘the conversion or transfer of property, knowing that such\n",
      "property is derived from any offence (s), to conceal or\n",
      "The associate editor coordinating the review of this manuscript and\n",
      "approving it for publication was Ines Domingues\n",
      ".\n",
      "disguise the illicit origin of the property or of assisting any\n",
      "person who is involved in such offence (s) to evade the legal\n",
      "consequences of his actions. ’’. Being a global issue, money\n",
      "laundering results in approximately 0.8 to 2.0$ trillion being\n",
      "laundered every year, which equates to 2 to 5% of the world’s\n",
      "GDP [1], [2]. Being a global issue, money laundering results\n",
      "in approximately 0.8 to 2.0$ trillion being laundered every\n",
      "year, which equates to 2 to 5% of the world’s GDP [2].\n",
      "50012\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Money laundering is the process of converting or transferring property that is derived from criminal activities to conceal or disguise its illicit origin. It often involves assisting individuals involved in such offenses to evade legal consequences. Globally, it is a significant economic issue, with approximately $0.8 to $2.0 trillion laundered each year, equating to 2 to 5% of the world's GDP.\n"
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T16:09:57.320843Z",
     "start_time": "2024-12-01T16:09:57.254075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from streamlit.runtime.scriptrunner import RerunException\n",
    "from streamlit.runtime.runtime import Runtime\n",
    "import streamlit as st\n",
    "\n",
    "def streamlit_app():\n",
    "    st.title(\"Hey there! I'm Scholarly. Ready to review your paper and give you feedback. Let’s get started!\")\n",
    "    uploaded_file = st.file_uploader('Upload your paper in .pdf format', type=\"pdf\")\n",
    "    if uploaded_file is not None:\n",
    "        graph = initialization(uploaded_file)\n",
    "    \n",
    "    with st.form(\"my_form\"):\n",
    "        text = st.text_area(\n",
    "            \"Enter text:\",\n",
    "            \"Should this paper be accepted?\",\n",
    "        )\n",
    "        submitted = st.form_submit_button(\"Submit\")\n",
    "        \n",
    "        if submitted:\n",
    "            graph.invoke({\"messages\": [\"Hi, Who are you?\"]})\n",
    "\n",
    "streamlit_app()"
   ],
   "id": "47444baceabb83fe",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 17:09:57.267 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-01 17:09:57.309 \n",
      "  \u001B[33m\u001B[1mWarning:\u001B[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/kuchikihater/Desktop/Scholarly/.venv/lib/python3.10/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-12-01 17:09:57.310 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-01 17:09:57.310 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-01 17:09:57.310 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-01 17:09:57.311 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-01 17:09:57.311 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-01 17:09:57.311 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-01 17:09:57.312 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-01 17:09:57.312 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-01 17:09:57.313 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-01 17:09:57.313 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-01 17:09:57.314 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-01 17:09:57.314 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-01 17:09:57.315 Session state does not function when running a script without `streamlit run`\n",
      "2024-12-01 17:09:57.315 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-01 17:09:57.316 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-01 17:09:57.316 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-01 17:09:57.317 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-01 17:09:57.318 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-01 17:09:57.318 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-12-01 17:09:57.319 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T16:10:04.141137Z",
     "start_time": "2024-12-01T16:10:04.101977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from streamlit.runtime.scriptrunner import RerunException\n",
    "from streamlit.runtime.runtime import Runtime\n",
    "\n",
    "Runtime()._start_web_server()\n"
   ],
   "id": "97b36e6d86fd2c05",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Runtime.__init__() missing 1 required positional argument: 'config'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[80], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mstreamlit\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mruntime\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mscriptrunner\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m RerunException\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mstreamlit\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mruntime\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mruntime\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Runtime\n\u001B[0;32m----> 4\u001B[0m \u001B[43mRuntime\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39m_start_web_server()\n",
      "\u001B[0;31mTypeError\u001B[0m: Runtime.__init__() missing 1 required positional argument: 'config'"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "d0bee98567f8652a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
