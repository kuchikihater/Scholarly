{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-05T17:02:48.522455Z",
     "start_time": "2024-12-05T17:02:47.602215Z"
    }
   },
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.chains import LLMChain, RetrievalQA, ConversationalRetrievalChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader, PyPDFLoader\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.vectorstores import Chroma, DocArrayInMemorySearch\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "new_api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T17:02:48.990753Z",
     "start_time": "2024-12-05T17:02:48.523974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embedding = OpenAIEmbeddings(api_key=new_api_key)\n",
    "vectordb = Chroma(persist_directory=\"db\", embedding_function=embedding)\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\", api_key=new_api_key, temperature=0.1)\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")\n",
    "     \n",
    "retriever=vectordb.as_retriever()\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory\n",
    ")"
   ],
   "id": "c6c3984739a17567",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v1/_150hm7j7kg24j8pzpqcx8vr0000gn/T/ipykernel_11206/4237593266.py:1: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding = OpenAIEmbeddings(api_key=new_api_key)\n",
      "/var/folders/v1/_150hm7j7kg24j8pzpqcx8vr0000gn/T/ipykernel_11206/4237593266.py:2: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectordb = Chroma(persist_directory=\"db\", embedding_function=embedding)\n",
      "/var/folders/v1/_150hm7j7kg24j8pzpqcx8vr0000gn/T/ipykernel_11206/4237593266.py:6: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T17:02:48.994407Z",
     "start_time": "2024-12-05T17:02:48.991631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_db(file, chain_type, k):\n",
    "    # load documents\n",
    "    loader = PyPDFLoader(file)\n",
    "    documents = loader.load()\n",
    "\n",
    "    # split documents\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "\n",
    "    # define embedding\n",
    "    embeddings = OpenAIEmbeddings(api_key=new_api_key)\n",
    "\n",
    "    # create vector database from data\n",
    "    db = DocArrayInMemorySearch.from_documents(docs, embeddings)\n",
    "\n",
    "    # define retriever\n",
    "    retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": k})\n",
    "\n",
    "    # create a chatbot chain. Memory is managed externally.\n",
    "    qa = ConversationalRetrievalChain.from_llm(\n",
    "        llm=ChatOpenAI(model_name=\"gpt-4\", api_key=new_api_key, temperature=0),\n",
    "        chain_type=chain_type,\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True,\n",
    "        return_generated_question=True,\n",
    "    )\n",
    "    return qa"
   ],
   "id": "8ddb4c7de7821888",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T17:05:19.573257Z",
     "start_time": "2024-12-05T17:05:14.072663Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import param\n",
    "\n",
    "class cbfs(param.Parameterized):\n",
    "    chat_history = param.List([])\n",
    "    answer = param.String(\"\")\n",
    "    db_query = param.String(\"\")\n",
    "    db_response = param.List([])\n",
    "\n",
    "    def __init__(self, **params):\n",
    "        super(cbfs, self).__init__(**params)\n",
    "        self.loaded_file = \"data/AML_IEEE_ACCESS_2024.pdf\"\n",
    "        self.qa = load_db(self.loaded_file, \"stuff\", 4)\n",
    "\n",
    "    def call_load_db(self, file_path=None):\n",
    "        \"\"\"Load a new database file.\"\"\"\n",
    "        if file_path:\n",
    "            self.loaded_file = file_path\n",
    "            self.qa = load_db(file_path, \"stuff\", 4)\n",
    "            self.clr_history()\n",
    "            print(f\"Loaded File: {self.loaded_file}\")\n",
    "        else:\n",
    "            print(f\"No file specified. Using default file: {self.loaded_file}\")\n",
    "\n",
    "    def convchain(self, query):\n",
    "        \"\"\"Process user query and update chat history.\"\"\"\n",
    "        if not query:\n",
    "            print(\"No query provided!\")\n",
    "            return\n",
    "        result = self.qa({\"question\": query, \"chat_history\": self.chat_history})\n",
    "        self.chat_history.append((query, result[\"answer\"]))\n",
    "        self.db_query = result[\"generated_question\"]\n",
    "        self.db_response = result[\"source_documents\"]\n",
    "        self.answer = result[\"answer\"]\n",
    "\n",
    "        print(f\"User: {query}\")\n",
    "        print(f\"LLM Chatbot: {self.answer}\")\n",
    "\n",
    "    def get_lquest(self):\n",
    "        \"\"\"Display the last database query.\"\"\"\n",
    "        if not self.db_query:\n",
    "            print(\"No database accesses so far!\")\n",
    "        else:\n",
    "            print(f\"Last question to DB: {self.db_query}\")\n",
    "\n",
    "    def get_sources(self):\n",
    "        \"\"\"Display the source documents from the last database response.\"\"\"\n",
    "        if not self.db_response:\n",
    "            print(\"No database response available!\")\n",
    "        else:\n",
    "            print(\"Result of DB lookup:\")\n",
    "            for doc in self.db_response:\n",
    "                print(f\"- {doc}\")\n",
    "\n",
    "    def get_chats(self):\n",
    "        \"\"\"Display the chat history.\"\"\"\n",
    "        if not self.chat_history:\n",
    "            print(\"No chat history yet!\")\n",
    "        else:\n",
    "            print(\"Chat History:\")\n",
    "            for user_query, bot_answer in self.chat_history:\n",
    "                print(f\"User: {user_query}\")\n",
    "                print(f\"Bot: {bot_answer}\")\n",
    "\n",
    "    def clr_history(self):\n",
    "        \"\"\"Clear the chat history.\"\"\"\n",
    "        self.chat_history = []\n",
    "        print(\"Chat history cleared.\")\n",
    "\n",
    "cb = cbfs()\n",
    "\n",
    "\n",
    "cb.convchain(\"What is the title of paper?\")\n",
    "\n",
    "cb.get_chats()\n",
    "cb.get_lquest()\n",
    "cb.get_sources()\n"
   ],
   "id": "b257111ec0baebd8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What is the title of paper?\n",
      "LLM Chatbot: The title of the paper is \"Scalable Semi-Supervised Graph Learning Techniques for Anti Money Laundering\".\n",
      "Chat History:\n",
      "User: What is the title of paper?\n",
      "Bot: The title of the paper is \"Scalable Semi-Supervised Graph Learning Techniques for Anti Money Laundering\".\n",
      "Last question to DB: What is the title of paper?\n",
      "Result of DB lookup:\n",
      "- page_content='2024 The Authors. This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License.\n",
      "For more information, see https://creativecommons.org/licenses/by-nc-nd/4.0/ VOLUME 12, 2024' metadata={'source': 'data/AML_IEEE_ACCESS_2024.pdf', 'page': 0}\n",
      "- page_content='of an AML model. Nevertheless, we hope the approach\n",
      "presented in this paper will make non-trivial contributions\n",
      "and give network security and financial crime analysis some\n",
      "insights into how to employ semi-supervised graph learning\n",
      "VOLUME 12, 2024 50027' metadata={'source': 'data/AML_IEEE_ACCESS_2024.pdf', 'page': 15}\n",
      "- page_content='in 2012, and the Ph.D. degree in applied cryptogra-\n",
      "phy from the University of Mannheim, Germany,\n",
      "in 2020. From 2013 to 2019, he was a Research\n",
      "Assistant in IT security with the Offenburg\n",
      "University of Applied Sciences, Germany. Since\n",
      "2019, he has been a Senior Researcher with\n",
      "the Fraunhofer Institute for Applied Information\n",
      "Technology FIT, Germany, where he is currently the Head of the Data\n",
      "Protection and Sovereignty Research Group. His research interests include\n",
      "improving data privacy and security in data-driven applications across\n",
      "different domains, such as cybersecurity, energy, and blockchain.\n",
      "VOLUME 12, 2024 50029' metadata={'source': 'data/AML_IEEE_ACCESS_2024.pdf', 'page': 17}\n",
      "- page_content='Received 20 February 2024, accepted 19 March 2024, date of publication 1 April 2024, date of current version 12 April 2024.\n",
      "Digital Object Identifier 10.1 109/ACCESS.2024.3383784\n",
      "Scalable Semi-Supervised Graph Learning\n",
      "Techniques for Anti Money Laundering\n",
      "MD. REZAUL KARIM\n",
      " 1,2, FELIX HERMSEN1,2, SISAY ADUGNA CHALA1,\n",
      "PAOLA DE PERTHUIS3,4, AND AVIKARSHA MANDAL\n",
      "2\n",
      "1Information Systems and Databases, RWTH Aachen University, 52074 Aachen, Germany\n",
      "2Department of Data Science and Artificial Intelligence, Fraunhofer FIT, 53757 Sankt Augustin, Germany\n",
      "3École Normale Supérieure (ENS), 75005 Paris, France\n",
      "4Cosmian, 75008 Paris, France\n",
      "Corresponding author: Md. Rezaul Karim (rezaul.karim@rwth-aachen.de)\n",
      "This work was supported by the Agence Nationale de la Recherche (ANR) and the Bundesministerium für Bildung und Forschung\n",
      "(BMBF) under the Franco-German AI Call for the project ‘‘CRYPTO4GRAPH-AI’’, grant number 01IS21100A.' metadata={'source': 'data/AML_IEEE_ACCESS_2024.pdf', 'page': 0}\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a4cf05a92b98847b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "27524dcbc66e1cb9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
